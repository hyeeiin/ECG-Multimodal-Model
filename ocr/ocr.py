from google.cloud import vision
import io
import re
import os
import pandas as pd
import glob

# # í™˜ê²½ ì„¤ì •
# os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "./vision_key.json"
# client = vision.ImageAnnotatorClient()


# # OCR í•¨ìˆ˜
# def extract_text_from_image(image_path):
#     with io.open(image_path, 'rb') as image_file:
#         content = image_file.read()
#     image = vision.Image(content=content)
#     response = client.text_detection(image=image)
#     texts = response.text_annotations
#     return texts[0].description if texts else ""

# # âœ… ëª¨ë“  health_record{ìˆ«ì}.png íŒŒì¼ ì°¾ê¸°
# image_files = sorted(glob.glob("health_image*.png"))

# # âœ… ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
# full_text = ""
# for image_file in image_files:
#     print(f"ğŸ” OCR ì²˜ë¦¬ ì¤‘: {image_file}")
#     text = extract_text_from_image(image_file)
#     full_text += "\n" + text

# print("--- OCR ê²°ê³¼ ---")
# # print(full_text)
# print("\nâœ… ì „ì²´ OCR ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ì•ë¶€ë¶„):\n")
# print(full_text[:1000])

# with open("ocr_result.txt", "w", encoding="utf-8") as f:
#     f.write(full_text)
# print("âœ… OCR ê²°ê³¼ê°€ ocr_result.txtì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

with open("ocr_result.txt", "r", encoding="utf-8") as f:
    full_text = f.read()

# ë³€ìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
def extract_value_from_window(lines, index, window=3):
    for offset in range(-window, window + 1):
        i = index + offset
        if 0 <= i < len(lines):
            nums = re.findall(r"\d{1,3}\.?\d*", lines[i])
            if nums:
                return nums[0]
    return ""

def extract_values(text):
    result = {k: "" for k in [
        "ì—°ë ¹", "ì„±ë³„", "ìˆ˜ì¶•ê¸°", "ì´ì™„ê¸°",
        "í¡ì—°", "ìŒì£¼", "ìš´ë™"
        "ê³¼ê±°ë³‘ë ¥", "í˜ˆìƒ‰ì†Œ", "ê³µë³µí˜ˆë‹¹", "ì´ì½œë ˆìŠ¤í…Œë¡¤", "ê³ ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤", "ì¤‘ì„±ì§€ë°©", "ì €ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤",
        "AST", "ALT",  "ê°ë§ˆì§€í‹°í”¼", "í˜ˆì²­ í¬ë ˆì•„í‹°ë‹Œ", "í‚¤", "ëª¸ë¬´ê²Œ"
    ]}
    lines = [line.strip() for line in text.split('\n') if line.strip()]

    # ì—°ë ¹ ì¶”ì¶œ
    for line in lines:
        m = re.search(r"ì—°ë ¹\s*[:ï¼š]?\s*(\d{1,3})\s*ì„¸", line)
        if m:
            result["ì—°ë ¹"] = int(m.group(1))
            break

    # ì„±ë³„ ì¶”ì¶œ
    for line in lines:
        if "ì„±ë³„" in line:
            if "ë‚¨" in line:
                result["ì„±ë³„"] = 0
            elif "ì—¬" in line:
                result["ì„±ë³„"] = 1
            break

    # í‚¤/ëª¸ë¬´ê²Œ ì¶”ì¶œ
    for i, line in enumerate(lines):
        if "í‚¤" in line and ("ëª¸ë¬´ê²Œ" in line or "ì²´ì¤‘" in line):
            nums = []
            for j in range(1, 4):
                if i + j < len(lines):
                    nums += re.findall(r"\d{2,3}\.?\d*", lines[i + j])
            if len(nums) >= 2:
                result["í‚¤"] = nums[0]
                result["ëª¸ë¬´ê²Œ"] = nums[1]
                
    for i, line in enumerate(lines):
        if "ê³ í˜ˆì••" in line:
            for j in range(1, 4):
                if i + j < len(lines):
                    m = re.search(r"(\d{2,3})\s*/\s*(\d{2,3})", lines[i + j])
                    if m:
                        result["ìˆ˜ì¶•ê¸°"] = m.group(1)
                        result["ì´ì™„ê¸°"] = m.group(2)
                        break
            break

    
    var_map = {
        "ê³µë³µí˜ˆë‹¹": ["ê³µë³µí˜ˆë‹¹", "í˜ˆë‹¹"],
        "ì´ì½œë ˆìŠ¤í…Œë¡¤": ["ì´ì½œë ˆìŠ¤í…Œë¡¤"],
        "ê³ ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤": ["ê³ ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤", "HDL"],
        "ì¤‘ì„±ì§€ë°©": ["ì¤‘ì„±ì§€ë°©"],
        "ì €ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤": ["ì €ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤", "LDL"],
        "AST": ["AST", "SGOT"],
        "ALT": ["ALT", "SGPT"],
        "í˜ˆìƒ‰ì†Œ": ["í˜ˆìƒ‰ì†Œ"],
        "í˜ˆì²­ í¬ë ˆì•„í‹°ë‹Œ": ["í¬ë ˆì•„í‹°ë‹Œ"],
        "ê°ë§ˆì§€í‹°í”¼": ["ê°ë§ˆì§€í‹°í”¼", "GTP"]
    }

    for var, keywords in var_map.items():
        for i, line in enumerate(lines):
            if any(kw in line for kw in keywords):
                val = extract_value_from_window(lines, i)
                if val:
                    result[var] = val
                    break

    # í˜ˆìƒ‰ì†Œ ë³´ì •
    if result["í˜ˆìƒ‰ì†Œ"] and '.' not in result["í˜ˆìƒ‰ì†Œ"]:
        for line in lines:
            if "í˜ˆìƒ‰ì†Œ" in line:
                m = re.findall(r"\d{1,2}\.\d", line)
                if m:
                    result["í˜ˆìƒ‰ì†Œ"] = m[0]
                    break
    
    # âœ… ìƒí™œìŠµê´€ í•­ëª© í†µí•© ì¶”ì¶œ
    lifestyle_keywords = {
        "í¡ì—°": "í¡ì—°",
        "ìŒì£¼": "ìŒì£¼",
        "ìš´ë™": "ìš´ë™"
    }

    current_section = None
    for line in lines:
        for key in lifestyle_keywords:
            if key in line:
                current_section = lifestyle_keywords[key]
                break

        if current_section and ("âœ…" in line or "â– " in line or "â˜‘" in line):
            result[current_section] = line.strip()
            current_section = None  # ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°
    
    # í¡ì—°
    if "ê³¼ê±° í¡ì—°ì" in result["í¡ì—°"]:
        result["í¡ì—°"] = 1
    elif "í˜„ì¬ í¡ì—°ì" in result["í¡ì—°"] or "ì „ìë‹´ë°°" in result["í¡ì—°"]:
        result["í¡ì—°"] = 2
    elif "ë¹„í¡ì—°ì" in result["í¡ì—°"]:
        result["í¡ì—°"] = 0

    # ìŒì£¼
    if "ë¹„ìŒì£¼ì" in result["ìŒì£¼"]:
        result["ìŒì£¼"] = 0
    elif any(word in result["ìŒì£¼"] for word in ["ì ì •", "ìœ„í—˜", "ì˜ì‹¬"]):
        result["ìŒì£¼"] = 1

    # ìš´ë™
    if result["ìš´ë™"] is not None:
        if "ê±´ê°•ì¦ì§„" in result["ìš´ë™"]:
            result["ìš´ë™"] = 2
        elif any(word in result["ìš´ë™"] for word in ["ê¸°ë³¸", "ì ì ˆ"]):
            result["ìš´ë™"] = 1
        elif any(word in result["ìš´ë™"] for word in ["ë¶€ì¡±"]):
            result["ìš´ë™"] = 0

    return result



# ë³€ìˆ˜ ì¶”ì¶œ
extracted = extract_values(full_text)

# ì¶œë ¥ ë° ì €ì¥
print("--- ì¶”ì¶œëœ ë³€ìˆ˜ ---")
for k, v in extracted.items():
    print(f"{k}: {v}")

df = pd.DataFrame([extracted])
df.to_excel("GoogleOCR_ì¶”ì¶œê²°ê³¼.xlsx", index=False)
print("ê²°ê³¼ê°€ GoogleOCR_ì¶”ì¶œê²°ê³¼.xlsxì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
