import openai
import base64
import re
import pprint
import json

def main(image_path, abnormal, arrhythmia, af, age, sex, height, weight, smoke, alcohol, physical, hx, fhx):

    # === 1. API í‚¤ ì„¤ì • ===
    # openai.api_key = "key"  # ğŸ” ì‹¤ì œ í‚¤ë¡œ êµì²´í•˜ì„¸ìš”

    # === 2. ì´ë¯¸ì§€ â†’ base64ë¡œ ì¸ì½”ë”© ===
    def encode_image_to_base64(image_path):
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")

    image_base64 = encode_image_to_base64(image_path)

    # clinical info
    abnormal = "ì •ìƒ" if abnormal == 0 else "ë¹„ì •ìƒ"
    arrhythmia = ", íŠ¹íˆ ë¶€ì •ë§¥" if arrhythmia == 1 else ""
    af = ", íŠ¹íˆ ì‹¬ë°©ì„¸ë™" if af == 1 else ""
    sex = "ì—¬ì„±" if sex == 1 else "ë‚¨ì„±"
    if smoke == 0:
        smoke = "ë¹„í¡ì—°ì"
    elif smoke == 1:
        smoke = "ê³¼ê±° í¡ì—°ì"
    else:
        smoke = "í˜„ì¬ í¡ì—°ì"
    alcohol = "ìŒì£¼ì" if alcohol == 1 else "ë¹„ìŒì£¼ì"
    if physical == 0:
        physical = "ìš´ë™ ë¶€ì¡±"
    elif physical == 1:
        physical = "ì €ê°•ë„ ìš´ë™"
    elif physical == 2:
        physical = "ì¤‘ê°•ë„ ìš´ë™"
    else:
        physical = "ê³ ê°•ë„ ìš´ë™"
    hx_text = ""
    if len(hx) != 0:
        for i in range(len(hx)):
            hx_text += hx[i]
            if i != len(hx) -1:
                hx_text += ", "
        hx_text += "ì˜ ê³¼ê±°ë ¥ì´ ìˆìŒ."
    fhx_text = ""
    if len(fhx) != 0:
        for i in range(len(fhx)):
            fhx_text += fhx[i]
            if i != len(fhx) -1:
                fhx_text += ", "
        fhx_text += "ì˜ ê°€ì¡±ë ¥ì´ ìˆìŒ."

    # === 3. ì‹œìŠ¤í…œ ì§€ì‹œ ë° ìœ ì € ë©”ì‹œì§€ êµ¬ì„± ===
    system_prompt = "ë„ˆëŠ” ì‹¬ì „ë„ë¥¼ í•´ì„í•  ìˆ˜ ìˆëŠ” ì„ìƒ ì˜ì‚¬ì´ë©° ECG ì „ë¬¸ê°€ì•¼."

    user_prompt = f"""
    í•´ë‹¹ ECG ì´ë¯¸ì§€ë¥¼ ë³´ê³  ëª¨ë¸ì´ {abnormal}{arrhythmia}{af}ì´ë¼ê³  íŒë‹¨í•œ ê²ƒì„ Grad-CAMì„ í†µí•´ì„œ ì–´ë”” ë¶€ë¶„ì„ ë³´ì•˜ëŠ”ì§€ heatmapìœ¼ë¡œ í‘œí˜„í•œ ê±°ì•¼.
    ì´ heatmapì„ ê·¼ê±°ë¡œ, ECG íŒŒí˜• ì¤‘ ì–´ë–¤ ë¶€ë¶„(RR ê°„ê²©, QRS íŒŒí˜•, TíŒŒ, PíŒŒ ë“±)ì— ì£¼ëª©í–ˆëŠ”ì§€ ì„¤ëª…í•˜ê³ , í•´ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ìƒì ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” íŒë‹¨ì„ ë‚´ë ¤ì¤˜.

    ë‹¤ìŒ í™˜ì ì •ë³´ë„ í•¨ê»˜ ê³ ë ¤í•´ì„œ í•´ì„í•´ì¤˜:
    - ë‚˜ì´: {age}ì„¸
    - ì„±ë³„: {sex}
    - í‚¤: {height}cm
    - ëª¸ë¬´ê²Œ: {weight}kg
    - í¡ì—° ì—¬ë¶€: {smoke}
    - ìŒì£¼ ì—¬ë¶€: {alcohol}
    - ì‹ ì²´ í™œë™: {physical}
    - ë³‘ë ¥: {hx_text}
    - ê°€ì¡±ë ¥: {fhx_text}

    ì•„ë˜ì™€ ê°™ì€ **í˜•ì‹ë§Œ ì°¸ê³ **í•´ì„œ ì‘ì„±í•´ì¤˜. ì‹¤ì œ ë‚´ìš©ì€ Grad-CAM ì´ë¯¸ì§€ì™€ í™˜ì ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡­ê²Œ ìƒì„±í•´ì¤˜:

    ì˜ˆì‹œ í˜•ì‹ (í˜•ì‹ë§Œ ì°¸ê³ , ë‚´ìš© ë³µë¶™ ê¸ˆì§€):

    ## ğŸ§  Grad-CAM + í™˜ì ì •ë³´ í•´ì„

    ### [RR ê°„ê²©]

    (Grad-CAMì—ì„œ RR ê°„ê²©ê³¼ ê´€ë ¨ëœ ì´ìƒ ì—¬ë¶€ + ì„ìƒì  í•´ì„)

    ---

    ### [QRS íŒŒí˜•]

    (QRSì˜ ì´ìƒ ì—¬ë¶€ ë° ê·¸ ì„ìƒì  ì˜ë¯¸)

    ---

    ### [TíŒŒ]

    (TíŒŒì— ëŒ€í•œ í•´ì„ ë° ì „í•´ì§ˆ ì´ìƒ, ì¬ë¶„ê·¹ ì¥ì•  ê°€ëŠ¥ì„± ë“±)

    ---

    ### [PíŒŒ]

    (PíŒŒì˜ ëª…í™•ì„± ì—¬ë¶€ ë° ë™ì„± ë¦¬ë“¬ ì—¬ë¶€ íŒë‹¨)

    ---

    ### [ì„ìƒ ê¶Œê³ ]

    - (Holter ë“± ì¶”ê°€ ê²€ì‚¬)
    - (ì‹¬ì´ˆìŒíŒŒ ë˜ëŠ” ì „í•´ì§ˆ íŒ¨ë„ ê²€ì‚¬)
    - (íŠ¹ì • ì¹˜ë£Œë‚˜ ìš´ë™ ì¡°ì ˆ ê¶Œê³  ë“±)
    """

    print(user_prompt)

    # === 4. GPT-4-vision API í˜¸ì¶œ (GPT-4 Turbo with vision) ===
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_base64}"
                        },
                    },
                ],
            },
        ],
        max_tokens=2048,
    )

    # === 5. ì¶œë ¥ ===
    print(response["choices"][0]["message"]["content"])
    gpt_output = response["choices"][0]["message"]["content"]

    # ì¶”ì¶œí•  ì„¹ì…˜ ì œëª©
    sections = ["RR ê°„ê²©", "QRS íŒŒí˜•", "TíŒŒ", "PíŒŒ", "ì„ìƒ ê¶Œê³ "]

    # ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ìƒì„±
    pattern = r"### \[(" + "|".join(sections) + r")\]\n(.*?)(?=\n### \[|\Z)"
    matches = re.findall(pattern, gpt_output, re.DOTALL)

    # ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
    section_dict = {section: "" for section in sections}
    for name, content in matches:
        section_dict[name] = content.strip().strip("---").strip()

    # ê²°ê³¼ ì¶œë ¥ ë° JSON ì €ì¥
    pprint.pprint(section_dict)

    # JSON ì €ì¥ (ì„ íƒ)
    with open("ecg_analysis_15.json", "w", encoding="utf-8") as f:
        json.dump(section_dict, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    image_path = "./abnormal_gradcam_15_overlay.png"
    abnormal = 1
    arrhythmia = 1
    af = 0
    age = 84
    sex = 1
    height = 143.8
    weight = 43.3
    smoke = 0
    alcohol = 0
    physical = 2
    hx = ["ë‡Œì¡¸ì¤‘", "ê³ í˜ˆì••"]
    fhx = []

    main(image_path, abnormal, arrhythmia, af, age, sex, height, weight, smoke, alcohol, physical, hx, fhx)