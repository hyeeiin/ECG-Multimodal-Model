# ğŸ«€ ECG Multimodal Classification

This project implements a **multimodal deep learning model** to classify ECG signals as **normal** or **abnormal** using:
- **ECG images**
- **ECG time-series signal (digitized)**
- **Clinical metadata**

---

## ğŸ“‚ Project Structure

ECG-Multimodal-Model/
â”œâ”€â”€ data/
      â”œâ”€â”€ images/
            â”œâ”€â”€ 1/
                â”œâ”€â”€ 001ECG_lead2.jpg
            â”œâ”€â”€ 2/
               ...
      â”œâ”€â”€ ecg_signals.csv
      â”œâ”€â”€ clinical.xlsx
      â””â”€â”€ labels.xlsx
â”œâ”€â”€ config.py
â”œâ”€â”€ dataset.py
â”œâ”€â”€ multimodal.py
â”œâ”€â”€ train.py
â”œâ”€â”€ checkpoints/
â”œâ”€â”€ runs/
â””â”€â”€ output/


---

## ğŸ“„ Data

- **images/**: Folder per patient, containing ECG images (`2500Ã—250`).
- **labels.xlsx**: Contains `index` and `label` (`normal`, `abnormal`, `borderline`).
  - `borderline` samples are **excluded** during training.
- **ecg_signals.csv**: Digitized ECG time-series (rows: index, columns: time points).
- **clinical.xlsx**: Includes `IDX` column for index and patient clinical metadata (e.g., age, sex, blood pressure, diabetes history).

All modalities must have **matching patient indices**. Missing indices (e.g., 17, 23, 36, ...) are automatically excluded.

---

## âš™ï¸ Key Files

| File | Description |
|------|-------------|
| `config.py` | Configuration for data paths, image size, hyperparameters, and device. |
| `dataset.py` | Loads all modalities, filters for common indices, excludes `borderline`, applies Z-score normalization, and creates stratified splits (train:val:test = 8:1:1). |
| `multimodal.py` | The multimodal model: ResNet18 for images (pretrained), MLP for ECG signals, MLP for clinical data, with feature fusion. |
| `train.py` | Full training pipeline with early stopping, dynamic learning rate adjustment, and TensorBoard logging. |

---

## ğŸš€ Usage

### 1ï¸âƒ£ Install environment

```bash
conda create -n ecgmm python=3.10
conda activate ecgmm
pip install pandas scikit-learn tqdm tensorboard
pip uninstall torch torchvision torchaudio -y
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 2ï¸âƒ£ Run TensorBoard
```bash
tensorboard --logdir=runs
```
http://localhost:6006/

### 3ï¸âƒ£ Train
```bash
python train.py
```

## ğŸ“ Reference

This project is inspired by:

**Anatomy-Informed Multimodal Learning for Myocardial Infarction Prediction**  
Ivan-Daniel Sievering, Ortal Senouf, et al.  
*IEEE Open Journal of Engineering in Medicine and Biology, 2024.*  
[Read on PubMed Central](https://pmc.ncbi.nlm.nih.gov/articles/PMC11573417/)
